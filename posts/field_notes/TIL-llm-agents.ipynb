{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3bd514b2",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"TIL from Stanford CME295 Transformers & LLMs | Lecture 7 - Agentic LLMs\"\n",
    "date: \"2025-12-26\"\n",
    "categories: \n",
    "    - Agentic LLMs\n",
    "    - RAG\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6596fd14",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## My notes and reflections on Lecture 7 - Agentic LLMs\n",
    "Lecture emphasises the shift from \"Prompt Engineering\" to \"Context Engineering\"\n",
    "\n",
    "### RAG is needed for fresh knowledge\n",
    "1. Model has knowledge cut-off and it is tricky to update it (think catastrophic forgetting, LoRA/ fine-tuning and doing it for every knowledge-update or use-case)\n",
    "2. even with large context windows of 100k-1M tokens, we still need **retrieval** because there are problems like:\n",
    "    - finding needle in haystack - high recall for single needle but for multiple needles (more real-world scenario) recall drops massively -> garbage in, garbage out still applies\n",
    "    - we have rate limits on #tokens; higher costs for more tokens; full corpus can't fit in context window. RAG reduces cost per token.\n",
    "\n",
    "### RAG pipeline\n",
    "\n",
    "1. Candidate Retrieval: Millions of chunks to hundreds of candidates using bi-encoder embeddings and Approximate Nearest Neighbors (ANN)\n",
    "    - Bi-Encoder: Query and document chunk encoded independently via SentenceBERT (SBERT) -> compute fast cosine similarity. Also called siamese\n",
    "    - Hybrid: embedding search + BM25 \n",
    "    - hyperparameters:Embedding size, chunk size, overlap between chunks\n",
    "2. Reranking (optional): rescore candidates using Cross-Encoder -> query and document fed simultaneously -> self-attention magic -> more accurate score than simple cosine similarity\n",
    "3. Context Composition: \n",
    "4. Generation\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "```{mermaid}\n",
    "flowchart LR\n",
    "    C[\"Retrieve <br>(High Recall w Hybrid)\"] --> D[\"Rerank <br>(High Precision w Cross-Encoder)\"]\n",
    "    D --> n1[\"Compose Context<br>(Clean, Dedup, Scope)\"]\n",
    "    n1 --> n2[\"Generate\"]\n",
    "``` "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef10b54",
   "metadata": {},
   "source": [
    "### High value tweaks to retrieval step\n",
    "- **Contextual Retrieval**: use cheap LLM to contextualize chunks to make them \"self-contained\"\n",
    "    - e.g., \"He won the election\" -> \"Donald Trump won the 2024 election...\" before embedding\n",
    "    - A chunk saying \"It increased by 5%\" is mathematically useless to an embedding model if the subject (\"Revenue\" or \"Churn\"?) was in the previous chunk.\n",
    "    - widely used, no added latency, solves for \"lost in the middle\" problem better than overlapping windows\n",
    "    - **Prompt Caching**: cache activations of static prompt prefixes saves costs (upto ~90%) -> when writing a prompt, put reusable part on top (system, instructions, examples, static context etc.) as it is *decoder* only\n",
    "\n",
    "\n",
    "- **HyDE**: generate fake document of query Q (as it is usually shorter, a question and doesn't look like document) and then compare with document embeddings\n",
    "    - niche, introduces latency\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50efde8d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### Eval metrics for Retrieval\n",
    "- NDGC (normalized discounted cumulative gain)\n",
    "    - NDCG@10:If the right answer is in the top 10 but at rank #9, your system effectively failed (users won't read it). NDCG penalizes this heavily.\n",
    "- MRR (mean reciprocal rank) - MRR (Mean Reciprocal Rank) is often more honest than Recall. Recall@10 says: \"We found the answer in the top 10 results!\" (Great, but if it was result #10, the LLM might have ignored it due to attention decay). MRR says:\"On average, the answer appeared at Rank 1.2.\" (This confirms the model actually saw the data).\n",
    "- MAP (mean average precision)\n",
    "- Precision@k: Did we fetch only relevant stuff, or did we pollute the context window with noise? (needle in haystack)\n",
    "- Recall@k: Did we find it at all?\n",
    "\n",
    "#### MTEB (Massive Text Embedding Benchmark)\n",
    "- for embedding model performance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2a4642",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### Tool Calling for Structured Data\n",
    "- tool calling for structured data / deterministic operations, modeled as functions with arguments and return values\n",
    "\n",
    "\n",
    "### Tool Selection\n",
    "- Classification problem. Model outputs a probability distribution over available tools or `null` (if no tool required)\n",
    "\n",
    "### MCP (Model Context Protocol)\n",
    "- sits between LLM and tool, integration logic is standardised\n",
    "- Standardizes how an LLM reads a PDF, a SQL row, or a Slack message. It replaces your custom def get_slack_messages(): function.\n",
    "- [Nov 2025 version](https://modelcontextprotocol.io/specification/2025-11-25)\n",
    "\n",
    "### Agents and ReAct (Reasoning + Acting) Framework\n",
    "- *Agent* is a system that autonomously pursues goals and completes tasks on a user's behalf\n",
    "- Traditional vs Reasoning vs Agent (tool calls)\n",
    "- `while goal is not achieved`: Observe -> Plan -> Act\n",
    "- in practice, ReAct -> LangGraph (state machine) - stricter\n",
    "- hallucinations are a (big) problem\n",
    "- agents interact with each other - A2A protocol (Google)\n",
    "    - It's gRPC/REST for Agents.\n",
    "    - Standardizes how a \"Travel Agent\" asks a \"Calendar Agent\" for availability. It handles the negotiation of intent, not just the reading of bytes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfec50d6",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### Safety and Guardrails\n",
    "\n",
    "- **Prompt Injection** - external content (e.g., website) are vulnerable to indirect prompt injection where hidden text on a webpage hijacks agent's instructions\n",
    "\n",
    "- **Guardrails** - lighter specialized models that can scan inputs/outputs for toxicity and policy violations before LLM processes them"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d092ef23",
   "metadata": {},
   "source": [
    "### strategy\n",
    "\n",
    "- Good to start simple, then iterate and progressively scale up\n",
    "- Good to start with capable models, optimize on size later\n",
    "- Transparency / observability helps with user trust and debuggability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc97f36f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### References\n",
    "\n",
    "\n",
    "- [Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks](https://arxiv.org/abs/1908.10084)\n",
    "    - The reason we can search 10M documents in milliseconds (pre-computed embeddings) vs. seconds (Cross-Encoders).\n",
    "- HyDE paper | [Precise Zero-Shot Dense Retrieval without Relevance Labels](https://arxiv.org/pdf/2212.10496)\n",
    "- Anthropic [Contextual Retrieval](https://www.anthropic.com/engineering/contextual-retrieval)\n",
    "- [Cross-Encoder](https://sbert.net/examples/cross_encoder/applications/README.html)\n",
    "- [Automatic Tool Selection to Reduce Large Language Model Latency](https://www.tdcommons.org/cgi/viewcontent.cgi?params=/context/dpubs_series/article/8702/&path_info=Automatic_Tool_Selection_to_Reduce_Large_Language_Model_Latency.pdf)\n",
    "- [MCP - Nov 2025 - specification](https://modelcontextprotocol.io/specification/2025-11-25)\n",
    "- ReAct paper | [ReAct: Synergizing Reasoning and Acting in Language Models](https://arxiv.org/abs/2210.03629)\n",
    "    - The \"While Loop\" of AI. The paper that proved LLMs perform better when they \"talk to themselves\" before acting.\n",
    "- [A2A: A New Era of Agent Interoperability](https://developers.googleblog.com/en/a2a-a-new-era-of-agent-interoperability/) | [Google's Agent2Agent Protocol (A2A)](https://a2a-protocol.org/latest/specification/)\n",
    "    - The first major attempt to standardize inter-agent communication (horizontal) rather than just tool communication (vertical)\n",
    "- [ToolSword: Unveiling Safety Issues of Large Language Models\n",
    "in Tool Learning Across Three Stages](https://arxiv.org/pdf/2402.10753)\n",
    "- [\"Towards Tool Use Alignment of Large Language Models\", Chen et al., 2024.](https://aclanthology.org/2024.emnlp-main.82.pdf)\n",
    "- [AGENT-SAFETYBENCH: Evaluating the Safety of\n",
    "LLM Agents](https://arxiv.org/pdf/2412.14470)\n",
    "- [Anthropic Cyber Attack](https://www.anthropic.com/news/disrupting-AI-espionage)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75cca425",
   "metadata": {},
   "source": [
    ">**Licensing Notice**: Text and media: [CC BY 4.0](https://creativecommons.org/licenses/by/4.0/); Code: [Apache License 2.0](http://www.apache.org/licenses/LICENSE-2.0)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
